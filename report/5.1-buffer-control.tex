\section{Controlling a buffer}
RxJava points out on its wiki page \cite{RxJava-Wiki-Backpressure} about backpressure that it does not make the problem of overproduction in the source go away. It claims to only move ``\textit{the problem up the chain of operators to a point where it can be handled better}''. To do so, they created the \textit{reactive pull} mechanism with operators like \code{onBackpressureBuffer} and \code{onBackpressureDrop}, such that the flow control is moved up to these kinds of operators.

We propose to move this flow control even further up the chain, up to the point where the source of the stream is drained in the pipeline of operators. Only there we can have maximum control over how much data is brought into the stream at a particular point in time. With this we do not have the need for infinite buffers as is the case in \code{onBackpressureBuffer}, nor do we have to drop unprocessed elements as is done with \code{onBackpressureDrop}. We propose to not wrap the cold source in the \code{Observable.create} (or any of its derived factory methods) but to wrap it in a universal, interactive interface. This way we are not dependent in our implementation on what kind of source we are dealing with. Given this interactive interface we can fill a bounded buffer with as many elements as can be processed at a particular point in time. The buffer pulls data from the source on behalf of the subscriber, which gets as much data pushed at it as it is able to handle. Pushing an element from the buffer to the downstream will automatically block the thread for another element to be pushed until the first one is fully processed.

To control the buffer's size, we will use feedback control. This makes total sense, as we don't know how fast the downstream is going to drain the buffer. However, it does not make any sense to give a certain size to the setpoint and compare the current size with it, as some `slow' consumers might go faster or slower than expected. Bounding the buffer to a certain fixed size defeats the purpose of the feedback system in this case, as we cannot dynamically grow or shrink the size as needed. On the other hand, it is also not possible to ask ``\textit{make sure the buffer is filled to its optimal size}''. A feedback system is not able to solve this, as it does not have a particular setpoint specified.

Instead of controlling the buffer size directly, we choose to measure the ratio between what goes out the buffer and what comes in the buffer. We will refer to this ratio as the system's throughput. In an optimal situation the amount of data that comes in is just as much as comes out of the system, so ideally this ratio must be $1.0$, which will be the setpoint of this system. Given the error that comes from the difference between the setpoint and the actual throughput, we can then determine how many elements to request from the source in the next iteration. The controller that does this will be discussed in a later section.

The full feedback system is depicted in \todo{refer to diagram}. Here it is also clearly visible that the source itself is \emph{not} part of the feedback system, but is \emph{used} by the system to retrieve a certain number of elements from. Also note that the \textit{downstream handler} is not part of feedback system. Even though it \emph{interacts} with the buffer, it is an external force that influences the behavior of the system. Ultimately the \textit{downstream handler} is the part that exposes an \obs for an \obv to listen to.

\todo{aankondiging: ``in de rest van deze section bespreken we de verschillende facetten van het feedback systeem''}

\todo{diagram of this feedback system}

\subsection{A universal, interactive interface}
As mentioned above, we propose to not wrap the (cold) source directly in \code{Observable.create}, but instead wrap it in a universal, interactive interface. This is necessary since there are many variants of interactive interfaces that all do the same, but each one in a slightly different way.

For example, the \itr interface has an \code{hasNext} and \code{next} method, which respectively check if there is a next element and return the next element. C\#'s \ier on the contrary has methods such as \code{moveNext}, which fetches the next element and returns whether there is a next element, and \code{current}, which actually returns the next element. For SQL database interaction, Java defines a \code{ResultSet}. This interface has a method called \code{next}, which moves the cursor to the next row of the result, and methods such as \code{getInt(int columnIndex)} and \code{getString(int columnIndex)} to get the content of a specific type from a column in the row the cursor is pointing to.

One thing these interfaces have in common is that they contain a method that fetches a single element and in the mean time block the thread it is operating on. If this fetch takes some time, your program will have to wait for the result to come in. To prevent this blocking behavior, we propose a universal interactive interface in which you request an element and subscribe to a stream on which \textit{eventually} this element will be emitted. Note that we separate the concerns of \textit{requesting} a next element and \textit{receiving} a next element. In this way, the program can still continue to operate and maybe do some other things while it is waiting for the requested element.

Given that we will use this interface in a feedback system that controls a buffer, we will pose an extra requirement on this interface. As the feedback system's controller might conclude that $n > 1$ elements need to be requested from the source, we must have to possibility to do so. Rather than $n$ times requesting 1 element, we want to request $n$ elements at once.

The complete interface is called \code{Requestable[T]} and is shown in \Cref{lst:universal-interactive-interface}. It contains a single abstract method \code{request(n: Int): Unit}, which is called whenever the user of this interface wants a certain number of elements from the source. The requested elements will at some point in time be emitted by the \obs that is returned by \code{results: Observable[T]}. If no more elements are available in the source, this \obs will terminate with an \code{onCompleted} event. The implementor of \code{Requestable} is expected to use the \code{subject} to bring elements in the stream, whereas the user of the interface is expected to observe \code{results} in order to get the requested data. Note that this is a \emph{hot} stream: element emission will not be repeated as a second \obv subscribes to the stream.

Example implementations of this interface for \itr and \code{ResultSet} are included in Appendix~\ref{appsec:requestable-interface}.

\begin{minipage}{\linewidth}
\begin{lstlisting}[style=ScalaStyle, caption={Universal, interactive interface used in the feedback system}, label={lst:universal-interactive-interface}]
trait Requestable[T] {

  protected final val subject $=$ PublishSubject[T]()

  final def results: Observable[T] $=$ subject

  def request(n: Int): Unit
}
\end{lstlisting}
\end{minipage}

\subsection{Implementing the feedback system}

\todo{use this equation somewhere in this subsection}
\begin{equation}
\tau_t = \frac{q_{t-1} - q_t + n_t}{q_{t-1} + n_t}
\end{equation}
