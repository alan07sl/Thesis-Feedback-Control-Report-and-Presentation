\chapter{An API for feedback control}

While studying the principles of feedback control, we discovered that there are hardly any publicly available libraries or APIs that abstract over the notions of feedback control, allowing us to create and execute feedback systems, both in simulation and in practice. Although surprising at first, this is completely in accordance with the earlier observation that feedback control is not (yet) a commonly used technique in computer science\footnote{Even though we were not able to find existing APIs for this purpose, we would not be surprised if companies turned out to have libraries like this in private.}. Surely, we can write the code ourselves as shown in \cref{sec:imperative-balltracker}, but that isn't really reusable, creates the danger of copy-paste behavior and is more prone to bugs than a dedicated API.

In this chapter we present our own API for creating and executing feedback systems that can potentially be used in production software. \todo{rest of the introduction and layout of this chapter}

\section{Related work}
One of the few libraries we found is described by Philip Janert in his book ``\textit{Feedback Control for Computer Systems}'' \cite{janert2013-feedback}. Janert presents a small framework for simulating feedback loops with the purpose of being a teaching tool that makes it simple and transparent to demonstrate the algorithms presented in several case studies and to encourage experimentation. He explicitly states that little emphasis was placed on elegant implementations or time efficiency and that this framework is not meant to be used in production software. What distinguishes his framework from other simulation frameworks for control systems (for example MatLab \todo{cite http://nl.mathworks.com/help/control/ref/feedback.html}), however, is the way that the components that make up a feedback loop are implemented. As discussed before, most feedback systems in physics and engineering are described in terms of complex mathematics, using transfer functions and Laplace transformations, that operate in the frequency domain. Janert's API, however, allows algorithms to be implemented in the time domain, which is a more natural representation to software developers and people that are not familiar to the mathematics based approach.

One of the central aspects of Janert's framework is the \code{Component} class which contains two methods with the following signatures: \code{def work(u: Double): Double}, which encapsulates the dynamic function of a component, called once every feedback cycle and \code{def monitoring: String}, which is just a convenience function and allows for a uniform approach to logging. All components (controlled systems, controllers and more advanced building blocks like actuators and filters) are just subclasses of \code{Component} that implement these two methods. The feedback system is then simulated using a loop that iterates over time stamps and which calls the \code{work} method on the next \code{Component} with the result of calling the \code{work} method of the previous \code{Component}. Finally at the end of each loop cycle the result is printed to the console using the \code{monitor} method of the \code{Component} that represents the system under control.

As pointed out by Janert, this framework does well for simulation but is not really useful for production software. One concern with this framework is that it performs a feedback cycle with regular intervals between each other. However, one can easily imagine a controlled system which produces a control output very irregularly. In that case the feedback cycle has to respond to the emission of a new data point rather than asking the controlled system for its next input. Another concern related to this is the ability to handle concurrency appropriately. A component in the feedback loop might perform some kind of timing related work that requires running on a different thread or thread pool. Finally we should note that the subclasses of \code{Component} have to use mutable state if they want to store any data. Think of the Integral Controller, which has to store its current sum. Mutable state is something that computer science has come to terms with as not being so practical in some cases as we once thought it would be. Especially when introducing concurrency, mutable state is something you want to avoid at all cost! \todo{keep these in mind when developing our own API and refer to these concerns there!}

\section{Towards a feedback API}
If we want to develop a library or API for feedback control we should keep a couple of things in mind. First of all the API should be production worthy: it should be able to drive production software/hardware and it should be easy for the developers of those systems to put together a feedback loop, without having to understand much about the mathematics that is going on in theoretical control theory. Also the concerns mentioned in the previous section should be kept in mind: the API should not rely on any form of mutable state if this is not desired by the developer, it should be easily able to support concurrency and asynchronicity and should not rely on any regularity in feedback cycles.

The idea by Janert to model a feedback system in the same way as it is drawn (see for example \cref{fig:balltracker-diagram}) is something that looks very appealing to use as a foundation of our API. This means that we create a feedback system by composing smaller entities or by chaining transformations. In the same way for example Scala's collection API is build up, using (monadic) operators to transform and manipulate a collection. Likewise we will use higher order functions to compose feedback systems.

Some of the basic composition operations that are required for this to work are \textit{sequential composition}, which passes the output of the first component as the input of the second component, \textit{parallel composition}, which passes its input to multiple components and combines the output of each component into a single value using a combinator function, \textit{merging the output of two components} into a single value and \textit{feeding back the output of a component to its input} to create a circuit or feedback loop. Other composition operators that one can imagine are operators like the ones found monadic APIs in Scala or Java 8 such as collections, \code{Future}, \code{Try}, \code{Option} or the Rx \obs. Examples of these are \code{map}, \code{filter}, \code{flatMap}, \code{take}, \code{drop}, \code{scan}, etcetera.

\subsection{Derivation}
To get to a suitable API we must first of all observe that a component can be thought of as a Mealy Machine \cite{mealy1955-mealymachine}. This is a special variant of the finite-state machine whose output values are determined by both its current input and its current state. It can mathematically be described as a 6-tuple $(\Sigma, \Gamma, S, s_0, \delta, \omega)$ \cite{carroll1989-theoryoffiniteautomata} where

\begin{itemize}
	\item $\Sigma$ denotes the input alphabet
	\item $\Gamma$ denotes the output alphabet
	\item $S$ denotes the finite nonempty set of states
	\item $s_0$ denotes the start (or initial) state; $s_0 \in S$
	\item $\delta$ denotes the state transition function; $\delta: S \times \Sigma \rightarrow S$
	\item $\omega$ denotes the output function; $S \times \Sigma \rightarrow \Gamma$
\end{itemize}

Note that the two functions $\delta$ and $\omega$ can be coalesced into a single function $\lambda: S \times \Sigma \rightarrow S \times \Gamma$.

This function $\lambda$ can also be written as a type definition in Scala:

\begin{lstlisting}[style=InlineScalaStyle]
type Component[S, I, O] $=$ (S, I) $\Rightarrow$ (S, O)
\end{lstlisting}

Notice that we use \code{I} and \code{O} to denote the input alphabet $\Sigma$ and output alphabet $\Gamma$ respectively. Equivalent to this type definition is the following static object \comp, containing a single function \code{apply}.

\begin{lstlisting}[style=InlineScalaStyle]
object Component {
  def apply[I, O, S](s: S, i: I): (S, O)
}
\end{lstlisting}

We can now rewrite \comp to be an interface and put the state \code{S} inside \comp implicitly. This removes the need for an input parameter of type \code{S} in the \code{apply} method, since the state is then contained inside the \code{this} pointer. Instead of the \code{S} in the return type we now, however, have to return a \comp that contains the output state.

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] {
  // (im)mutable state in here
  def apply(i: I): (Component[I, O], O)
}
\end{lstlisting}

Instead of returning a tuple, the \code{apply} method can be split into two separate methods. \code{update} will accept something of input type \code{I} and return a new \comp, containing its new state. The output value of the transformation on the original component together with \code{I} can be retrieved from the newly returned \comp using the \code{action} method.

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] {
  // (im)mutable state in here
  def update(i: I): Component[I, O]
  def action: O
}
\end{lstlisting}

This version of \comp gives us a first suitable implementation for composing over components. We will refer to this version as the \textit{Immutable Component}. Notice that this version is actually used in our blog post ``\textit{Feedback Control for Hackers}'' \cite{heest2015-feedback-for-hackers} as the basis of the simulation framework used in several case studies.

As an example of a component that inherits this interface, we will show an implementation of a component that maintains a running average of its input elements.

\begin{lstlisting}[style=ScalaStyle]
class RunningAverage(n: Int, queue: Queue[Double])
      extends Component[Double, Double] {

  def update(u: Double): RunningAverage $=$ {
    if (queue.length $==$ n) queue.dequeue
    queue.enqueue(u)

    new RunningAverage(n, queue)
  }

  def action: Double $=$ queue.sum / queue.length
}
\end{lstlisting}

Here the internal state of the \comp, that was earlier referred to as \code{S}, consists of both the integer \code{n} (representing the number elements over which it has to calculate the running average), and the queue containing at most the latest \code{n} numbers that it received. Notice that \code{Component[Double, Double]} here specifies that the input type (the data type it can receive over which it calculates the average) and the output type (the data type of the average) are both \code{Double}. The \code{action} method is the one that calculates the actual average using the numbers that are present in the queue. On the other hand, receiving of the next value as well as keeping the queue up to date are done by the \code{update} method, which returns a new instance of \code{RunningAverage} with the new state of the queue, including the new element and excluding the oldest element (if the queue's size is equal to \code{n}).

The observant reader will already have noticed the striking similarity between the \textit{Immutable Component} and the \code{Component} interface by Janert \cite{janert2013-feedback}. In fact, our latest \comp interface is the immutable variant of his interface. For this, we have to change the output type of the \code{update} function to \code{Unit} and perform the action of updating the internal state of the \comp as a side-effect. The new state will no longer be returned, but is included in the instance of \comp itself. We will refer to this variant of the interface as the \textit{Mutable Component}.

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] {
  // mutable state in here
  def update(i: I): Unit
  def action: O
}
\end{lstlisting}

Using this \textit{Mutable Component} interface we can implement \code{RunningAverage} again. Rather than having the \code{queue} as a constructor parameter, we can now treat it as a field that is automatically instantiation on construction. With this we can mutate the queue when \code{update} is called. Notice that for this we either need to use a mutable queue here or declare the field mutable by using a \code{var}. Finally, the implementation of \code{action} doesn't change with respect to the former version.

\begin{lstlisting}[style=ScalaStyle]
class RunningAverage(n: Int) extends Component[Double, Double] {

  val queue $=$ Queue[Double]()

  def update(u: Double): Unit $=$ {
    if (queue.length $==$ n) queue.dequeue
    queue.enqueue(u)
  }

  def action: Double $=$ queue.sum / queue.length
}
\end{lstlisting}

Using the \textit{Mutable Component}, calling the \code{work} method in Janert's \comp interface is equivalent to calling \code{update} and \code{action} in sequence. To conform to this interface, we can write our \comp as shown below. In technical terms this is called the coproduct, which we have already seen briefly in \cref{subsec:derivation}.

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] {
  // mutable state in here
  def update(i: I): O
}
\end{lstlisting}

As Janert already concluded, this interface is fairly suitable for simulation purposed, but does is not meant for production services. Although it is possible to use this interface in production, it would mean that we would introduce a fair bit of mutable state, which is not the most desirable thing in todays distributed systems, microservice architecture or APIs. Besides that, the implementer of this \comp interface has to deal with concurrency all by himself if he wants to make sure that no race conditions or other concurrency side effects happen.

Rather than letting the implementer deal with these issues, we think that the interface should be as simple as possible and that the implementer should only have to focus upon the actual behavior of a certain \comp. All the concurrency, scalability, fault tolerance should be handled by the interface and operations for composing instances of this interface which we will discuss later.

In order to move toward this goal we will again perform a couple of transformations on our \comp interface. We first of all require \textit{continuation-passing-style}, which transforms a regular function with input $A$ and output $B$ into a function that takes a second argument which is a function from the output type $B$ to $C$:

\[A \rightarrow B \ \ \ \ \Leftrightarrow \ \ \ \ (A, B \rightarrow C) \rightarrow C\]

The new function's second argument is called the continuation, which specifies what to do with the original function's output afterwards. In the code below we define two functions \code{f} and \code{g} to be the original function and the continuation-passing-style function respectively. We also define a function \code{h} which transforms a \code{B} into a \code{Unit}. With this we can show that first calling \code{f} and then \code{h} gives us the same result as calling \code{g} with \code{h} as its second parameter.

\begin{lstlisting}[style=InlineScalaStyle]
def f(a: A): B
def g(a: A, cont: B $\Rightarrow$ Unit): Unit
def h(b: B): Unit

h(f(a)) $==$ g(a, h)
\end{lstlisting}

A second transformation that we require is the notion of currying, which is derived from category theory, known as a \textit{Cartesian closed category}. We will not go into the mathematical details, but just focus on the application in the field of programming, types and function. Currying basically means that you can split a list of function parameters into an equivalent series of functions. For example, given a function \code{f} with parameters of type \code{A} and \code{B} and return type \code{C}, we can define an equivalent function \code{g} which is the curried form of \code{f}:

\begin{lstlisting}[style=InlineScalaStyle]
def f(a: A, b: B): C
def g(a: A)(b:B): C
\end{lstlisting}

Function \code{f} in this example has type \code{(A, B) $\Rightarrow$ C}, which is equivalent to the type of \code{g}: \code{A $\Rightarrow$ B $\Rightarrow$ C}. Notice that the latter is a function with a single argument of type \code{A} and returns another function with a single argument of type \code{B} and a return type \code{C}.

We will use now use continuation passing style and currying in the continuation of our derivation. So far we have an interface which similar to the one presented in Janert's book.

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] {
  // mutable state in here
  def update(i: I): O
}
\end{lstlisting}

First of all, we can apply continuation passing style and take the output type \code{O} as the input of a function which will be a second input parameter of the new \code{update} method.

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] {
  // mutable state in here
  def update(i: I, f: O $\Rightarrow$ Unit): Unit
}
\end{lstlisting}

With this new interface we could potentially chain one \comp to another, by calling the \code{update} method of the second \comp in the second input parameter of the first. This however would ugly pretty fast, as lots of components would mean lots of nested functions, which are not very pleasant for the eye. What we will do instead is continue by observing that \code{update} has two parameters, which means that we can apply currying and decompose the parameter list.

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] {
  // mutable state in here
  def update(i: I)(f: O $\Rightarrow$ Unit): Unit
}
\end{lstlisting}

Now that we have a function \code{update} with type \code{I $\Rightarrow$ (O $\Rightarrow$ Unit) $\Rightarrow$ Unit}, we can use the right associativity law on functions and conclude that \code{update} can also be read as a function which has input type \code{I} and output \code{(O $\Rightarrow$ Unit) $\Rightarrow$ Unit}. Although this return type doesn't seem so useful at first sight, we must remember that this is almost identical to the actual type definition of \obs (see \cref{eq:obs}). The major difference is in the input type of the inner function, which is not \code{Try[Option[O]]} but just \code{O} instead. However, it seems perfectly reasonable that the computation inside a \comp may fail or terminate all computation inside that \comp. Following this reasoning, we can now write our interface as follows:

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] {
  // mutable state in here
  def update(i: I): Observable[Unit]
}
\end{lstlisting}

Although one could stop here and develop operations for composing and executing instances of this interface, we will continue with some more transformations in order to further optimize the upcoming API around this interface. We must observe first of all that there is still mutable state involved in this interface, which we have concluded before we want to minimize as much as possible. Secondly, when sequentially composing two instances of this interface together, we have a way for the \code{OnNext}s of the first instance to go into the second, but we have no possibility to propagate an \code{OnError} or \code{OnCompleted} event from the first instance to the second.

In order to achieve these goals, we next apply the inverse of a coproduct, called a \code{product} in categorical terms, to split the \code{update} method into two methods \code{in} and \code{out}, which accept the input parameter \code{I} and return the \code{Observable[O]} respectively.

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] {
  // mutable state in here
  def in(i: I): Unit
  def out: Observable[O]
}
\end{lstlisting}

Notice that when concatenating multiple instances of \comp, we only call \code{out} once while setting up the chain, whereas \code{in} gets called every time the previous component emits an element. As discussed before, these emissions only involve the \code{OnNext} events, since the \code{OnError} and \code{OnCompleted} events have nowhere to go. Now that we have split \code{update} into two separate methods, we can easily add extra methods for these missing events. Rather than doing that directly, however, we can equally well use the official way to add these methods, which is by inheriting \comp from \obv, which already contains these three methods all together.

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] extends Observer[I] {
  // mutable state in here
  def out: Observable[O]
}
\end{lstlisting}

To get this to work, there is a little bit of plumbing to be done. First of all, we need to get the values received in the \obv into the output \obs and meanwhile transform instances of type \code{I} into instances of type \code{O}. As we do not intent the implementer of the \comp interface to override the input or output functions, we have to introduce a new function into the interface in which the actual functionality of the component can be declared: \code{transform(is: Observable[I]): Observable[O]}. We also introduce a \subj which receives the input events from the \obv methods. As discussed in \cref{subsec:subjects}, a \subj is both an \obv and an \obs, which means that we can implement the output function as applying the new \code{transform} function to this \subj.

\begin{lstlisting}[style=InlineScalaStyle]
trait Component[I, O] extends Observer[I] {
  val subject $=$ Subject[I]()
  override val _subscription $=$ subject._subscription
  
  def transform(is: Observable[I]): Observable[O]
  def asObservable: Observable[O] $=$ transform(subject)
  
  override def onNext(value: I): Unit $=$ subject.onNext(value)
  override def onError(e: Throwable): Unit $=$ subject.onError(e)
  override def onCompleted(): Unit $=$ subject.onCompleted()
}
\end{lstlisting}

Having set up the \comp interface in this way, comes with an extra benefit. By using the \code{transform} method that converts one \obs into another, we can leverage the operators defined on \obs to bring the mutable state of the \comp into the sequence of operators. We will demonstrate the implementation of a \comp and the usage of mutable state by following up on the earlier example of the running average.

\begin{lstlisting}[style=ScalaStyle]
class RunningAverage(n: Int) extends Component[Double, Double] {

  def transform(input: Observable[Double]): Observable[Double] $=$ {
    input.scanLeft(new Queue[Double]) { case (queue, value) $\Rightarrow$ 
        if (queue.length $==$ n)
          queue.dequeue()
        queue $+=$ value
      }
      .drop(1)
      .map(queue $\Rightarrow$ queue.sum / queue.size)
  }
}
\end{lstlisting}

Implementing a component is just as simple as creating a class that extends \comp and implementing the \code{transform} function. In the case of \code{RunningAverage} the input stream contains numbers of which the average needs to be calculated for the last \code{n} received elements. The mutable state of the queue is wrapped in the \code{scanLeft} operator\footnote{RxJava/RxScala calls this method \code{scan}, whereas other implementations such as Rx.NET and RxMobile call it \code{scanLeft}}, in which the queue gets updated. Since the \code{scanLeft} emits the initial empty queue as its first element, we drop this element before proceeding. Finally we transform the queue into the running average inside the \code{map} operation.

Based on this interface we think we can present a good foundation for the interface of this feedback API. The concerns we had with the API by Janert are fixed in this interface. Mutable state is no longer required as the \obs provides operators to deal with them. Concurrency issues are dealt with by the \obs as well, as discussed in earlier chapters. Finally, the \comp does not run on an externally defined clock but is triggered when it receives an event.

































































\clearpage
\todo{content here}

\begin{itemize}
	\item Since we do feedback control for computer science, we want to come up with an API to create feedback systems
	\begin{itemize}
		\item A good API does not yet exist
		\item Some simple stuff in Python
		\item Solution from Peti Koch
	\end{itemize}
	\item Introduce the ball tracker as a toy example
	\begin{itemize}
		\item First on 1 dimension; implemented with for-loops etc.
		\item Use this throughout the rest of the Feedback Control section
	\end{itemize}
	\item Feedback control as ‘working with streams’
	\begin{itemize}
		\item A component sits in between 2 streams and performs some sort of transformation
		\item A component is compositional: connecting components, making feedback loop, zipping $\rightarrow$ a feedback system is the same as a component
		\item Observation: \textbf{a component is the same as a Mealy Machine}
		\item Derive the exact type of a component, starting from a Mealy Machine and using category theory
		\item Observation: \textbf{a component is an Arrow}
		\item Introduce the operators on Component
		\begin{itemize}
			\item Arrow operators (see \LaTeX code)
%			\begin{itemize}
%				\item \code{arr :: Arrow a => (b -> c) -> a b c}
%				\item \code{(>>>) :: Arrow a => a b c -> a c d -> a b d}
%				\item \code{first :: Arrow a => a b c -> a (b,d) (c,d)}
%				\item \code{second :: Arrow a => a b c -> a (d,b) (d,c)}
%				\item \code{(***) :: Arrow a => a b c -> a d e -> a (b,d) (c,e)}
%				\item \code{(\&\&\&) :: Arrow a => a b c -> a b d -> a b (c,d)}
%				\item \code{lift2A :: Arrow a => (b -> c -> d) -> a e b ->   a e c -> a e d}
%				\item \code{loop :: Arrow a => a (b,d) (c,d) -> a b c}
%			\end{itemize}
			\item Concat
			\item Zip
			\item Feedback
			\item \textit{$<$many RxMobile operators$>$}
			\item Lift and LiftA2 (as generalizing over all operators)
		\end{itemize}
		\item Ball tracker example with the API
	\end{itemize}
\end{itemize}

\todo{below in chap4 with looking back on chap3?}
The ultimate goal in computer science (especially in software engineering) is to wrap the theory of a piece of technology in some kind of an API, such that anybody can incorperate it easily in their applications, platforms or frameworks. The notion of feedback control is however apparently so foreign to computer science that there does not exist a proper API for this yet. 